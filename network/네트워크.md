## 프로토콜이란?

컴퓨터간 데이터 통신을 원활히 하기 위한 통신 규약이다. 신호 송신의 순서(handshaking) 나 데이터 표현법, 오류 검출법 등을 정한 것이다.

## HTTP 프로토콜이란?

Hypertext Transfer Protocol의 약자로, 하이버텍스트를 전송하기 위한 통신 규약이다.
하이퍼텍스트: 참조(하이퍼링크)를 통해 독자가 한 문서에서 다른 문서로 즉시 접근할 수 있는 텍스트이다.
비연결성 프로토콜, Requst에 대한 response만 전달되고 연결은 유지되진 않는다.

## 비연결성을 해결하기 위한 방법

> HTTP는 요청간 연결을 유지하지 않는 프로토콜이다. 즉, 클라이언트가 어떤 사용자였는지 서버는 매번 기억하지 못해서 "로그인 유지" 같은 상태 유지 기능이 필요할 때, 쿠키, 세션을 통해 클라이언트를 식별하고 상태를 유지한다.

1. Cookie/Session(stateful): Cookie에 클라이언트에 대한 정보를 저장했다가 사용거나, Session에 사용자 정보를 저장해서 유지하는 방식
2. Session Storage / Local Storage

- Session Storage: HTML5에서 제공, 세션 스토리지는 세션이 유지되고 있을 때까지 브라우저 내부 저장소에 저장하고 세션이 끊기면 자동으로 없어진다.
- Local Storage: 사용자나 프론트엔드 내부적으로 삭제를 하지 않는 이상 영구적으로 저장된다.

## [HTTP 1.1과 HTTP 2.0의 차이점](../meail-mail/2025-06-15.md)

http 1.1

- keep-alive 로 tcp 연결 유지하여 RTT 감소
- 파이프라이닝 기법으로 요청하여 성능 개선했지만 요청의 순서를 보장하는 tcp 특성상 Hol Blocking 발생
- 무거운 헤더를 매 요청마다 반복적으로 전송

http 2.0

- 멀티플렉싱으로 애플리케이션 계층의 hol blocking 해결, 패킷을 프레임으로 쪼개어 스트림으로 전송하여 서버에서 요청에 대한 순서를 보장하지 않아도 됨
- HPACK 이라는 헤더 업축 방식을 통해 데이터 전송량 줄이고, 대역폭 사용 최적화
- 서버 푸시하여 클라이언트가 요청하려는 데이터를 미리 보내주어 성능 최적화

### 예시로 보는 멀티 플렉싱

1. 요청/응답 하나를 스트림(Stream) 이라고 부름
2. 그 스트림을 **여러 개의 프레임(Frame)**으로 쪼갬
3. 각 프레임에 Stream ID를 붙임
4. 이 프레임들을 TCP 바이트 스트림으로 섞어서 전송 (interleaving)
5. 수신 측은 Stream ID를 보고 프레임들을 분류하고 조립

```pgsql
GET /hello
Header: Content-Type: application/json
Body: { "message": "hi" }
```

1. 하나의 스트림(Stream)을 생성 (예: Stream ID = 1)
2. 이 스트림 안에 들어갈 데이터를 **여러 프레임(Frame)**으로 쪼갬:
   - HEADERS 프레임 → 헤더 정보 포함
   - DATA 프레임 → 본문 데이터 포함
3. 이 프레임들을 TCP로 쪼개서 전송

🔁 이때 중요한 점:  
여러 요청을 동시에 보내더라도 각 요청은 독립된 스트림으로 처리됨 (ID로 구분)  
한 스트림의 프레임은 순서대로 도착해야 하지만,
다른 스트림의 프레임과는 교차(interleave) 되어도 됨

## HTTPS 프로토콜이란

> 애플리케이션 계층과 전송 계층 사이에 신뢰 계층은 SSL, TLS 계층을 넣은 신뢰할 수 있는 HTTP 요청을 말한다.

HTTP + SSL, HTTP 통신하는 소켓을 SSL(Secure Socket Layer) or TLS(Transport Layer Security) 라는 프로토콜로 대체하는 것(새로운 별개의 프로토콜이 아니라 연결 방식이 달라진 것이다)
HTTP는 TCP와 직접 통신하지만, HTTPS에서는 SSL과 통신하고 SSL이 TCP와 통신하는 방식
대칭키 암호화 방식과 공개키 암호화 방식을 혼합한 하이브리드 암호 시스템 사용, 공개키를 공개키 암호와 방식으로 교환하고 이후 통신은 대칭키 암호를 사용하는 방식

애플리케이션 과 전송 계층 사이에 SSL, TLS 계층을 두고 데이터(정확히는 애플리케이션에서 전송하는 데이터)~~애플리케이션의 페이로드~~를 암호화하여 전송하는 방식이다.

## HTTPS 통신 과정

HTTPS통신 과정에서는 디피-헬만 키 교환 알고리즘을 사용한다.

> 디피-헬만 키 교환 알고리즘은 처음에 공개 값을 공유하고 각자의 비밀 값과 혼합한 후 혼합값을 공유한다. 그 다음 각자 비밀 값과 또 혼합한다. 이후 공통의 암호키인 PSK(Pre-Shared Key)(=세션키)가 생성

### Certbot을 통해 인증서 받기

- [공식 사이트](https://eff-certbot.readthedocs.io/en/stable/using.html#)
- [블로그](https://bitgadak.tistory.com/6)

## 1. Certbot 이란

> Cerbot은 EFF 가 인터넷 전체를 암호화하려는 노력의 일환이다. 웹에서 신뢰기반 통신을 하기 위해 HTTPS를 사용하는데, 이는 브라우저가 웹 서버의 신원을 확인할 수 있도록하는 디지털 인증서를 사용해야한다(서버가 믿을만한 서버인지 확인하는 과정을 인증서로 진행). 웹 서버는 인증 기간(CA)라는 신뢰할 수 있는 제 3자로부터 인증서를 받는다. Certbot은 EFF, Mozilla 등이 출시한 공개 인증 기과인 Let’s Encrypt에서 인증서를 가져와 웹 서버에 배포하는 사용하기 쉬운 클라이언트이다.
> Certbot과 Let's Encrypt는 이러한 번거로움을 자동화하여 간단한 명령으로 HTTPS를 활성화하고 관리할 수 있도록 지원합니다. Certbot과 [Let's Encrypt](https://letsencrypt.org/getting-started/)는 무료로 사용할 수 있습니다.

즉, Certbot을 사용해서 인증 기관에서 무료로 인증서를 발급받을 수 있다는 말이다.

Certbot은 PC가 아닌 배포된 웹 서버에서 명령줄을 통해 직접 실행해야한다. 호스팅 서비스를 이용 중이고 웹 서버에 직접 접근할 수 없는 경우 Certbot을 사용하지 못한다.

Certbot을 사용하기 위해 필요한 조건

1. command line 실행할 수 있어야한다
2. http로 동작중이고, 온라인 상태이며 80포트를 사용중이다.
3. ssh로 접근 가능하고 sudo 권한이 있으며
4. 서버가 호스팅되어야한다 → 도메인 이름(서버이르)존재 + 공개 IP , Certbot은 인터넷에 접근 가능한 웹서버가 있어야 SSL 인증서를 발급해 줄수 있다(AWS EC2, 가상 서버 호스팅, 클라우드 서버 등)

## 2. Nginx 활용

> 왜 NGINX: 서버에 톰캣이라는 WAS가 있어서 톰캣에도 인증서를 적용할 수 있지만, WAS는 애플리케이션 실행만 처리하도록 하고, 웹 서버를 따로 두어 WAS의 부하를 막기 위해서 Nginx를 따로 두었다.
> Nginx가 리버스 프록시 역할을 해서 톰캣은 내부망에서 Http로 운영하고 Nginx는 퍼블릭 서브넷에 위치하여 보안을 확보.
> WAS는 Nginx를 통해서만 접근이 가능하고 외부에서 직접적으로 접근하지 못함.

- nginx를 사용한 이유 정리

  1. WAS 부하 막기

     SSL 암호화/복호화 비용은 큰작업이므로 이를 톰캣이 실행한다면 애플리케이션 성능에 영향을 줄 수 있다.

     Nginx가 SSL 먼저 처리하고(세션키로 대칭키 통신), 내부 톰캣은 암호화 해제된 요청만 받게 하여 부하 분산

  2. 성능 최적화

     정적 파일은 Nginx가 하도록 하여 빠르게 처리하도록 하였다.

     Nginx는 비동기 이벤트 기반 구조라서 동시 접속 처리 성능이 뛰어나다.

     톰캣은 도적 처리에 강하지만, 정적 파일 처리에는 느리다.

  3. 로드 밸런싱

     여러대의 톰캣 앞에 nginx를 뒤서 로드 밸런싱

     특정 URI에 대해서는 서버로 포워딩하여 서버 부하를 방지

  4. 보안 설정이 용이

     IP 제한, Rate limiting, Bot 차단 등 보안 기능을 프론트에서 설정 가능

     WAF(웨 방화벽)처럼 확장해서 활용 가능

nginx의 /etc/nginx/sites-available 폴더에 default.conf를 생성해서 도메인 연결과 TLS 통신을 위한 인증서 설정

nginx는 nginx.conf를 바탕으로 동작하므로 인증서 등록하는 설정파일을 따로 둔다면 nginx.conf에 등록해주어야한다.

```bash
http {
    include /etc/nginx/conf.d/*.conf;
    include /etc/nginx/sites-enabled/*.conf;
    include /etc/nginx/sites-enabled/my_own_conf;

		...
}
```

- [nginx 설정 파일 구조](https://nginx.org/en/docs/beginners_guide.html)
- [nginx의 기본 설정 파일 nginx.conf 다시 작성하면서 동작 원리 깨닫기](https://www.youtube.com/watch?v=7VAI73roXaY)
- [nginx 설정 에러 10가지](https://nginxstore.com/blog/nginx/%EA%B0%80%EC%9E%A5-%EB%A7%8E%EC%9D%B4-%EC%8B%A4%EC%88%98%ED%95%98%EB%8A%94-nginx-%EC%84%A4%EC%A0%95-%EC%97%90%EB%9F%AC-10%EA%B0%80%EC%A7%80/)

```bash
server {
    listen 80;
    server_name yourdomain.com www.yourdomain.com;

    # HTTP 요청을 HTTPS로 리다이렉트
    return 301 https://$host$request_uri;
}

server {
    listen 443 ssl;
    server_name yourdomain.com www.yourdomain.com;

    ssl_certificate /etc/letsencrypt/live/yourdomain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/yourdomain.com/privkey.pem;

    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    location / {
        proxy_pass http://<tomcat-private-ip>:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}

```

## 3. 인증서 얻기

1. 인증서 얻기 + 자동 설치, 인증서 업데이트 → certbot (certbot run 과 동일)
2. 인증서 얻기 + 수동 설치 → cerbot certonly

```bash
# Obtain and install a certificate:
certbot

# Obtain a certificate but don't install it:
certbot certonly

# You may specify multiple domains with -d and obtain and
# install different certificates by running Certbot multiple times:
certbot certonly -d example.com -d www.example.com
certbot certonly -d app.example.com -d api.example.com
```

위 명령어 실행 후 `Successfully recited certificate` 라는게 뜨고 인증서가 어디에 저장되었는지 나온다

생성된 모든 키와 발급된 인증서는 에서 찾을 수 있습니다 . `/etc/letsencrypt/live/$domain`여기서 `$domain`는 인증서 이름입니다.

Cerbot이 알고 있는 인증서 목록을 보려면 cerbot certificates 명령어로 확인 할 수 있다.

```bash
Found the following certificates:
  Certificate Name: example.com
    Domains: example.com, www.example.com
    Expiry Date: 2017-02-19 19:53:00+00:00 (VALID: 30 days)
    Certificate Path: /etc/letsencrypt/live/example.com/fullchain.pem
    Key Type: RSA
    Private Key Path: /etc/letsencrypt/live/example.com/privkey.pem
```

## 4. nginx에 인증서 적용

위에서 발급 받은 인증서를 nginx에 적용

nginx의 경우 비밀키를 fullchain.pem을 사용해야한다.

```bash
server {
    listen       80;
    listen       443 ssl;
    server_name  crudewebtools.com;

    ssl_certificate     /etc/letsencrypt/live/crudewebtools.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/crudewebtools.com/privkey.pem;

    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
    }

    location = /50x.html {
        root   /usr/share/nginx/html;
    }
}
```

ssl_certificate: 서버의 공개키(엔드엔트리 인증서) + 루트 인증서까지의 체인이 저장된 파일

Nginx에 [ssl_certificate_key 가](https://nginx.org/en/docs/http/ngx_http_ssl_module.html#ssl_certificate_key) 필요 → 이게 서버의 비밀키이다

- **privkey.pem (서버의 비밀키)**
  인증서의 개인 키. → 이게 노출되면 안된다.
- **fullchain.pem(서버의 공개키, CA로 부터 인증받은 = end entry 인증서)**
  서버 인증서를 포함한 모든 인증서, nginx에서 ssl_certificate에 필요한 인증서이다.
- **`cert.pem`그리고 `chain.pem`(CA의 루트 인증서와 서버 인증서를 이어주는 인증서 체인) → 이게 있어야 클라이언트에서 루트 인증서를 가지고 체인을 따라서 서버 인증서와 연결되어 있는지 확인**
  cert.pem은 서버 인증서를 자체적으로 포함하고 있으며, chain.pem은 서버 인증서를 검증하기 위해 웹 브라우저에 필요한 추가 중간 인증서 또는 인증서를 포함하고 있습니다

certbot은 RSA 및 ECDSA 두가지 비밀키 알고리즘을 지원한다.

2.2.0버전에서는 모든 인증서에 ECDSA secp256r1 인증서 개인키를 기본으로 사용한다

### 정리

certbot에서 인증서 발급받는 과정

1. certbot 이라는 명령어를 사용해서 인증서를 발급받고 자동으로 설치해준다.
2. 이때 인증서가 발급받아지는데, 간단하게 3개로 이루어져 있다.
   1. 서버 비밀키에 해당하는 privkey.pem
   2. 서버 공개키와 CA 루트 인증서와 연결된 정보를 담고 있는 chain.pem을 합친 fullchain.pem(TLS 핸드셰이크에서 클라이언트에게 보내는 인증서 체인 전체)
   3. 서버 공개키 자체 엔드 엔트리 인증서인 cert.pem
   4. 서버 공개키와 CA 루트 인증서를 연결하는 정보를 담고 있는 파일인 chain.pem

여기서 fullchain.pem을 클라이언트에게 보내어 세션키를 만들어 대칭키 기반 암호화 통신을 할 수 있습니다.

클라이언트는 브라우저에 내장된 **신뢰할 수 있는 루트 인증서 저장소**

를 바탕으로 fullchain.pem 안의 **엔드 엔트리 인증서(`cert.pem`)가 루트 인증서까지 신뢰 체인을 형성하는지 검증** 합니다.

검증이 완료되면, 클라이언트는 서버의 공개키(엔드 엔트리 인증서 안에 포함됨)를 사용하여 **세션키(대칭키)를 암호화해서 서버에 전송하고**, 이후에는 그 세션키를 바탕으로 **대칭키 기반 암호화 통신(예: AES)** 을 수행합니다.

## 인증서 갱신

Let’s encrypt에서 발급하면 인증서 유효기간은 3개월이다. →

certbot 의 경우에도 갱신을 위한 명령어가 존재한다.

그런데, 위 과정을 거쳐 certbot 을 통해 인증서를 발급 받은 경우, 자동으로 만료되기 20 일 전 쯤 갱신을 해준다.

해당 예약 명령은 systemd.timer 에 등록되어 있다.

확인해 보자.

```
# systemctl list-timers
NEXT                         LEFT       LAST                         PASSED       UNIT                         ACTIVATES
Sun 2022-01-30 01:32:00 KST  49min left n/a                          n/a          snap.certbot.renew.timer     snap.certbot.renew.service
Sun 2022-01-30 22:55:40 KST  22h left   Sat 2022-01-29 22:55:40 KST  1h 46min ago systemd-tmpfiles-clean.timer systemd-tmpfiles-clean.service

2 timers listed.
Pass --all to see loaded but inactive timers, too.
```

서버에 별 문제가 생기지 않는다면 자동으로 알아서 계속 갱신해 줄 것이다.

## TLS 핸드셰이크(TLS 1.2 기준)

TLS 1.2 - RSA방식: 클라이언트가 세션 키를 생성하고, 서버의 **공개키로 암호화해서 전송**

1. 서버가 비대칭키를 생성하여 공개키를 CA에게 제출하고, CA로부터 인증 서명을 받는다.
2. 클라이언트로부터 Https 요청이 오면 인증서를 전달한다. 클라이언트는 해당 서명이 믿을만한 CA로부터 인증받은 것인지 확인한다(CA의 공개키로)
3. 인증이 완료되면 클라이언트는 서버의 public 키를 획득하고, 세션 키를 암호화하고, 서버에 전달한다.
4. 서버는 암호화된 세션키를 받아서 서버의 프라이빗키로 복호화하고, 세션키를 획득한다.
5. 클라이언트와 서버는 동일한 세션키를 획득하고 이걸로 신뢰를 기반한 HTTP 송수신을 한다. (세션키로 데이터 암호화 복호화)

### 보안 세션

보안 \*세션이란 보안이 시작되고 끝나는 동안 유지되는 세션을 말하고, SSL/TLS는 핸드셰이크를 통해 보안 세션(세션키)을 생성하고 이를 기반으로 상태 정보 들을 암호화하여 공유한다.

\*세션이란 운영체제가 어떠한 사용자로부터 자신의 자산 이용을 허락하는 일정 기간을 뜻한다. 즉, 사용자는 일정 시간 동안 응용 프로그램, 자원 등을 사용할 수 있다.

### CA 발급 과정

자신의 서비스가 CA 인증서를 발급받으려면 자신의 사이트 정보와 공개키(서버)를 CA에 제출해야한다. 이후 CA는 공개키를 해시한 값인 지문(서명)을 사용하는 CA의 비밀키 등을 기반으로 CA 인증서를 발급한다.

### 암호화 알고리즘

키 교화 알고리즘으로는 대수곡선 기반의 ECDHE(Elliptic Curve Diffie-Hellman Ephermeral) 또는 모듈식 기반의 DHE(Diffie-Hellman Ephermeral)를 사용한다.  
둘다 디피-헬만(Diffie-Hellman)방식을 근간으로 만들어졌다.

#### 디피-헬만 키 교환 암호화 알고리즘

암호키를 교화하는 하나의 방법이다. TLS 핸드셰이크에서 디피-헬만 키 교화 알고리즘이 사용된다.

## TLS 핸드셰이크(TLS 1.3 기준)

서버와 클라이언트의 연결이 완료된 시점. TCP 연결 완료(1-Rount Trip Time이 생긴후)

1. 클라이언트가 자신의 임시 공개키(ECDHE)와 https 요청(어떤걸로 암호화하겠다 등등) -> clientHello
2. 서버는 요청을 받고 자신의 임시 공개키(ECDHE)와 인증서와 가능한 암호화 목록을 보낸다 -> serverHello
3. 클라이언트는 인증서를 인증하고 서버의 임시 공개키 + 자신의 개인키 로 세션키(PSK) 계산, 서버도 자신의 개인키 + 클라이언트의 임시 공개키로 PSK 계산
   - 서버는 PSK = ECDHE(server_private_key, client_public_key)
   - 클라이언트는 PSK = ECDHE(client_private_key, server_public_key)
   - 위 두개의 PSK는 동일

TLS 1.3 - Ephemeral Diffie-Hellman 기반 (Forward Secrecy 지원)은 클라이언트와 서버가 각자 임시 공개키/개인키 쌍을 생성하고 서로 공개키만 교환, 둘이 **공동 계산을 통해 세션 키(PSK)를 생성**

- 서버와 클라이언트는 각각 임시 키 쌍을 생성 (예: ECDHE).
- 둘 다 **상대의 공개키 + 자신의 개인키**를 사용해서 **같은 세션 키(PSK)를 계산**.
- 이 키는 외부에 노출되지 않으며, **양쪽에서 계산된 값이 일치함**.
- 공격자는 공개키만 보고는 PSK를 계산할 수 없음.  
  클라이언트와 서버 모두 개인키와 공개키를 생성하고, 서로에게 공개키를 보내고 공개키와 개인키를 결합하여 PSK가 생성되면, 공격자가 개인키 또는 공개키를 가지고도 PSK가 없기 때문에 아무것도 할 수가 없다.

## HTTP Request - GET 과 POST의 차이점

- GET: 서버에 데이터를 전달할 때 URL Query를 사용해야 하므로 보안에 취약함 / 데이터를 받는 용도로 적합
- POST: 데이터를 Body에 넣어서 전송하므로 body를 열어보지 않으면 확인할 수 없다 / DB내용을 갱신하거나 서버로 데이터를 전송할 때 적합
- SSL 을 이용한 HTTPS 프로토콜로 데이터 전송을 암호화하면 보안성을 보완할 수 있다. URL 뒤에 붙는 쿼리스트링 내용 모두 암호화되어 전송되기 때문에 보안성을 강화함

## Restful API 에서의 URL과 일반적인 HTTP에서의 URL의 차이는?

- 일반적인 HTTP URL은 기능에 중심을 두고 설계하고
- Restful API는 리소스에 중점을 두고 설계한다. 슬래시("/")를 사용하여 하위 관계를 표현하고 POST, GET, PUT, PARCH, DELETE HTTP 메서드를 사용한다.

## TCP/UDP 포트 목록

> IANA(Internet Assigned Numbers Authority)는 인터넷 할당 번호 관리기관의 약자로 IP 주소, 최상위 도메인 등을 관리하는 단체이다

잘 알려진 포트(well-known port)는 특정한 쓰임새를 위해서 IANA에서 할당한 TCP 및 UDP 포트 번호의 일부이다. 일반적으로 포트 번호는 다음과 같이 세 가지로 나눌 수 있다.

- 0번 ~ 1023번: 잘 알려진 포트 (well-known port)
- 1024번 ~ 49151번: 등록된 포트 (registered port)
- 49152번 ~ 65535번: 동적 포트 (dynamic port)

| 프로토콜 | 포트   | 설명                                                                                                                                  |
| -------- | ------ | ------------------------------------------------------------------------------------------------------------------------------------- |
| HTTP     | 80     | 웹을 지원하기 위한 프로토콜로, GET, PUT같은 프로토콜 기능을 포함해서 웹 서버에게 어떠한 content를 요청하고 또는 웹 서버로 정보를 꺼냄 |
| FTP      | 20, 21 | TCP를 활용해 대량의 파일을 송신하고 수신하는 프로토콜                                                                                 |
| TFTP     | 69     | UDP를 사용하는 파일 전송 프로토콜, 라우터나 스위치 등의 네트워크 장비의 IOS 이미지를 업로드, 다운로드 할 때 사용                      |
| Telenet  | 23     | 원격지에 있는 장비로 표준 터미널 에뮬레이션 기능을 제공함. 네트워크 장비에서는 텔넷을 통해 원격지에서 장비를 설정                     |
| SMTP     | 25     | 컴퓨터 네트워크를 통해 전자메일을 전송하는 프로토콜, 받을 때는 POP3를 활용                                                            |
| SNMP     | 161    | 네트워크 장비를 모니터링하고 제어하기 위해 사용하는 프로토콜로 네트워크 장애 관리, 장비 설정, 통계 성능 및 보안 등을 관리             |
| DNS      | 53     | 도메인 주소를 IP Address로 변경, 모든 퍼블릭 IP 주소화 호스트 이름은 DNS에 저장되고 나중에 IP 주소로 변환                             |

## 웹 통신의 큰 흐름: https://www.google.com/ 을 접속할 때 일어나는 일

면접 단골 문제입니다. 면접관 입장에서는 한 질문으로 많은 답변을 들을 수 있기 때문에 대부분의 면접자리에서 나왔던 문제입니다. OSI 7계층과도 연관지어 설명하라는 질문을 받은적도 있습니다.

www.naver.com으로 요청을하면 맨 처음에 브라우저 캐시와 리버스 프록시 서버에 캐시가 있는지 확인하고 없다면 DNS Resolver의 캐시를 확인합니다. 그것도 없으면 DNS Resolver가 Root Server 부터 Name Server 까지 Recursive 과정으로 ip를 알아냅니다.

이 요청은 프로토콜 스택이라는 OS에 내장된 네트워크 제어용 소프트웨어에 의해 패킷에 담기고 패킷에 제어정보를 덧붙여 LAN 어댑터에 전송하고, LAN 어댑터는 이를 전기신호로 변환시켜 송출합니다.

패킷은 스위칭 허브 등을 경유하여 인터넷 접속용 라우터에서 ISP로 전달되고 인터넷으로 이동합니다.  
액세스 회선에 의해 통신사용 라우터로 운반되고 인터넷의 핵심부로 전달됩니다. 고속 라우터들 사이로 목적지까지 패킷이 흘러들어가게 됩니다.

핵심부를 통과한 패킷은 목적지의 LAN에 도착하고, 방화벽이 패킷을 검사한 후 캐시 서버로 보내어 웹 서버에 갈 필요가 있는지 검사합니다.

웹 서버에 도착한 패킷은 프로토콜 스택이 패킷을 추출하여 메시지를 복원하고 웹 서버 애플리케이션에 넘깁니다. 애플리케이션은 요청에 대한 응답 데이터를 작성하여 클라이언트로 회송하고, 이는 전달된 방식 그대로 전송됩니다.

### DNS 서버

1. **Root** Server : **`.`** 중 **`.com`** 은 **A TLD 서버**로 가시오 + **`.net`** 은 **B TLD 서버**로 가시오
2. **TLD** Server : **`.com`** 중 **`naver.com`** 은 **C NS** 로 가시오 + **`daum.net`** 은 **D NS** 로 가시오
3. **NS, Name Server** : naver.com 중 finance.naver.com 은 E Server 로 가시오
   - Authoritative Server 라고 부름
     - Non-Authoritative 의 의미는 캐싱되어있는 DNS 를 반환했다는 뜻
     - Authoritative 의 의미는 캐싱되어있지 않은 실제 NS 에 저장된 실시간 DNS 를 반환

### 키워드

리다이렉트, 캐싱, DNS, IP 라우팅, TCP 연결 구축 -> 응답이 일어나는 TTFB(Time to First Byte)가 시작-> 컨텐츠를 다운 -> 브라우저 렌더링 과정 -> 네이버 화면

TCP 연결 후 콘텐츠 다운로드 받게되는 시점이 시작될 때를 TTFB 라고 한다. 요청해서 콘텐츠 다운로드 처음 시작할때..

![브라우저 요청 흐름](브라우저요청흐름.png)

해당 요청이 캐싱가능하면 캐싱값을 반환하고, 최초의 요청이라면 다음 단계로 넘어간다.

우리 애플리케이션 서버도 application layer임. 그래서 naver.com으로 요청이 오면 리다이렉트 -> 캐싱(브라우저 캐싱, 프라이빗 캐싱) -> dns 서버 -> ip라우팅해서 tcp 연결 후 1계층가지 갔다가 -> 목적지인 서버에 도달하기 위해 1계층부터 올라사거 tcp서버에서 요청 받기위한 스레드, 서블릿 생성(컨트롤러) -> 비즈니스 로직 수행 -> 데이터 반환 -> 서블릿, 스레드 destroy하고 tcp 연결끊기(4way handshake)

크롬에서 "캐시된 데이터 삭젝" 여기서 캐시는 브라우저 캐시를 의미

DNS: 계층적인 도메인 구조와 분산된 데이터베이스를 이용한 시스템, dns관련 요청을 네임서버로 전달하고 응답을 클라리언트에게 전달하는 리졸버, 도메인을 IP로 변환하는 네임서버 등으로 이루어짐
FQDN(Fully Qualified Domain Name): 호스트와 도메인이 합쳐진 완전한 도메인 이름 www 등을 호스트, naver.com은 도메인
DNS 쿼리가 오면 역순으로 root dns -> .com dns -> .naver dns -> .www dns 과정을 거쳐 완벽한 주소를 찾아 IP 주소를 매핑한다.

### DNS 캐싱

해당 도메인을 요청한 적이 있다면 로컬 PC에 자동적으로 저장된다. 브라우저 캐싱과 OS캐싱이 있는데, 크롬 같은 경우 chrome://net-iternals/#dns
OS캐싱(window) ipconfig/displaydns 에 있다.

### DNS 조회 순서

1. 브라우저 DNS 캐시: 브라우저 내부에 저장된 도메인-IP 매핑 정보 확인
2. OS DNS 캐시: 브라우저에 캐시가 없다면 OS가 유지하는 DNS 캐시 확인
3. 호스트 파일(hosts 파일)

- macOS/Linux: /etc/hosts
  여기에 수동으로 설정된 도메인이 있다면 해당 IP 사용

4. 로컬 DNS 서버(예: 공유기 또는 ISP 제공 DNS) -> ISP 가 제공하는 DNS Resolver 내 캐시로 이해
   위 캐시에 없으면, 설정된 DNS 서버로 질의
5. 최종적으로 DNS 리졸버가 DNS 서버 질의
   DNS 리졸버가 로컬 DNS 서버에 없으면 루트 DNS -> TLD DNS -> Name Server

### DNS Resolver가 IP 조회하는 과정

1. DNS Resolver 내 DNS 캐시를 확인
2. 캐시에 가져오려는 도메인 네임과 일치하는 것이 없다면 Name Server 까지 Recursive 조회 수행, 있다면 캐시에서 가져온 내용을 반환(Non-Authoritative)
3. 캐시 없다면 naver.com 도메인에 대한 IP를 얻기위해 재귀조회를 한다.
4. Root Server에서 .com에 대한 다음 서버 경로를 얻고
5. TLD Server에서 naver.com에 대한 다음 서버 경로를 얻고
6. Name Server에서 naver.com에 대한 IP 주소를 얻는다.

이후 IP주소를 얻으면 DNS 리졸버가 클라이언트에게 IP 주소를 반환한다.

DNS 서버에서 IP 주소를 반환받고 IP라우팅(SYN 패킷을 보내기 위함)을 통해 패킷 경로를 설정해준다. 이후 TCP 연결을 시도하고 연결이 성공하면 이때 IP 계층에서 TCP 세그먼트를 목적지로 라우팅한다.
연결에 성공하면 IP주소를 기반으로 요청 패킷을 라우팅한다.
여기에 라우터라 라우팅을 설정해준다.

### 라우터란

물리계층, 데이터링크 계층, 네트워크 계층으로만 이루어진 네트워크 장비로, packet을 전달하고 라우팅하여 네트워크 간 통신을 중계해주는 역할을 한다.
라우터가 하는 일은 2가지

1. forwarding: input port로 들어온 패킷을 라우터의 output port로 전달하는 역할, 라우팅 테이블을 참고해서 output port를 결정한다.
2. routing: 네트워크의 구조와 목적지까지의 최적 경로를 계산하는 제어 동작.라우터 간에 제어 메시지를 주고받아 라우팅 정보를 교환하고,
   이를 통해 라우팅 테이블을 업데이트한다.

라우터에 L1,L2,L3계층만 있는 이유가 뭐야? 패킷 라우팅에 L1도 필요한가?
yes, 실제 데이터를 주고 받기 위해서 전기/광 신호로 전달해야함

### DNS에서 IP를 찾은 과정까지 완료되었다면 TCP 연결과정 시작 (SYN 패킷 전달 과정)

1. TCP 연결시도

- 목적지 IP를 알았으니 TCP 연결을 위해 SYN 패킷 생성
- 이 패킷은 TCP 세그먼트 -> IP 패킷 -> 이더넷 프레임으로 감싸짐 (이 과정을 캡슐화)

2. 패킷이 계층을 따라 내려간다(L4 -> L3 -> L2 -> L1)
   L4: 포트 번호 포함, SYN 설정
   L3: 목적지 IP 설정, 필요한 헤더 설정 등
   L2: ARP로 MAC 주소 찾고, 설정 (다음 홉 결정)
   L1: 전기/광 신호로 변경하여 실제 전송 수단
3. 라우팅 시작

- 이더넷 프레임으로 감싸진 프레임은 실제 물리 계층(L1) 을 통해 전송
- 프레임은 1차적으로 게이트웨이(라우터)로 전송
- 프레임 전달 받은 라우터는 아래 역할 수행
  1. MAC 헤더 제거(L2 계층 처리)
  2. IP 헤더보고 다음 홉 결정(L3 계층 라우팅)
  3. 새 MAC 헤더(다음 홉) 붙여서 다음 라우터로 전달
     - 만일 라우터가 private subnet에 있다면 게이트웨이 역할을 하는 라우터의 MAC주소를 얻는다.
  4. 위 과정 반복하면서 최종 목적지 서버까지 간다.

4. 목적지 도착 후 TCP 연결 수립

- 목적지 서버가 SYN-ACK 응답
- 다시 역방향으로 프레임 전송 -> 최종 ACK -> 연결 완료

## 우리집에서 요청한 패킷이 가정용 라우터로 전달될텐데, 어떻게 밖으로 나갈 수 있을까?

ISP가 제공해주는 지역 접속 장비 덕분

1. 내 컴퓨터에서 패킷을 보낼 때,
2. 패킷은 먼저 지역 접속 장비(예: DSLAM, OLT, CMTS 등)으로 전달, 이 장비를 여러 가정의 트래픽을 모아서 ISP 내부망으로 보낸다.
3. 지역 접속 장비에서 받은 패킷은 ISP의 핵심 라우터(Core Router)로 전달
4. 핵심 라우터가 목적지 IP를 확인하고, 최적의 경로를 찾아서
5. 다음 홉(다른 ISP 라우터, 해외 라우터 등)으로 패킷을 라우팅

### ISP는 어떤 역할을 수행할까?

특정 지역헤서 발생하는 네트워크 요청을 다른 지역, 나라에게 전달
**www.naver.com이 국내 타지역 서버인 경우**

1. 내 컴퓨터 → 지역 접속 장비 → ISP 라우터
2. ISP 라우터가 IP 주소를 보고 해당 지역의 다른 접속 장비나 라우터로 패킷을 전달
3. 최종적으로 목적지 서버가 위치한 데이터센터까지 국내망 내에서 라우팅 완료

**www.google.com이 미국 서버인 경우**

1. 내 컴퓨터 → 지역 접속 장비 → ISP 라우터
2. ISP 라우터가 목적지 IP가 해외임을 인지
3. ISP 백본망을 거쳐, 국제 해저 광케이블가 연결된 라우터(해외 게이트웨이)로 패킷 전달
4. 해저 광케이블 통해 미국 ISP 라우터로 전송
5. 미국 ISP 내부망 및 구글 서버까지 라우팅 완료

## 간단 설명

www.naver.com으로 요청을하면 맨 처음에 브라우저 캐시와 리버스 프록시 서버에 캐시가 있는지 확인하고 없다면 DNS Resolver의 캐시를 확인합니다. 그것도 없으면 DNS Resolver가 Root Server 부터 Name Server 까지 Recursive 과정으로 ip를 알아냅니다.
IP를 알아냈다면 해당 IP를 기반으로 tcp 연결을 하기 위해 ip라우팅을 해서 tcp 연결을 한 후 연결에 성공하면 패킷을 라우팅을 합니다.
패킷은 스위칭 허브 등을 경유하여 인터넷 접속용 라우터에서 ISP로 전달되고 인터넷으로 이동합니다.  
액세스 회선에 의해 통신사용 라우터로 운반되고 인터넷의 핵심부로 전달됩니다. 고속 라우터들 사이로 목적지까지 패킷이 흘러들어가게 됩니다.
웹 서버에 도착한 패킷은 프로토콜 스택이 패킷을 추출하여 메시지를 복원하고 웹 서버 애플리케이션에 넘깁니다. 애플리케이션은 요청에 대한 응답 데이터를 작성하여 클라이언트로 회송하고, 이는 전달된 방식 그대로 전송됩니다.

## TCP 연결 3way handshake

## TCP 연결해제 4way handshake

## VPN과 VPC

https://medium.com/harrythegreat/aws-%EA%B0%80%EC%9E%A5%EC%89%BD%EA%B2%8C-vpc-%EA%B0%9C%EB%85%90%EC%9E%A1%EA%B8%B0-71eef95a7098  
VPN은 virtual private network의 약자로 가상으로 나눠진 네트워크를 말합니다. 실제 물리 네트워크는 연결되어 있지만 논리적으로 다른 네트워크 처럼 동작합니다. 그래서 보안이 중요한 곳에서는 공용 네트워크에 VPN으로 터널링을 하는 경우가 있는데, 공용 인터넷을 통해 암호화된 통신 터널을 만들고, 마치 사설 네트워크처럼 안전하게 데이터를 송수신할 수 있게 해주는 기술로 활용됩니다.

VPC는 virtual private cloud의 약자로, 클라우드 제공자가 사용자에게 제공하는 가상 네트워크 공간이라고 할 수 있습니다. 사용자가 직접 IP 대역, 서브넷, 라우팅, 방화벽 등을 정의해서 **프라이빗 네트워크처럼 설계**할 수 있음예를 들어서 AWS EC2는 모두 AWS 데이터 센터 하나에 있지만 사용자는 EC2를 각자 자신만의 데이터 센터에서 서버를 구성할 수 있는 것이 AWS에서 제공하는 VPC라고 할 수 있습니다.
