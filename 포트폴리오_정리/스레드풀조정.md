# 스레드 풀 개수 조정 근거

핵심은 CPU의 노는 시간을 최대한 줄이도록 쓰레드 개수를 조정하면 된다.

## 쓰레드 풀의 적정 크기

스레드 수 = CPU 코어 수 × U × (1 + waitTime / serviceTime) -> Brian Goetz가 Java Concurrency in Practice에서 말한 공식이다. 이를 풀어서 설명하면 아래와 같다.

```
- 대기 시간: IO, 락 획득, 네트워크 응답 등으로 인해 CPU를 사용하지 않고 대기하는 시간
- 서비스시간: 실제 연산자(CPU-bound) 작업을 수행하는 시간
- 1+waitTime/serviceTime =  스레드 수를 증가시켜 CPU가 놀지 않고 계속 일하도록 보상하는 계수
 U(활용률): 1이면 100% 사용, 0.8이면 80% 목표

CPU 수: 4개
평균적으로: 1개의 스레드는 20ms 동안 CPU를 쓰고 이후 80ms는 I/O 응답을 기다림
→ wait / service = 80 / 20 = 4
→ 적정 스레드 수 ≈ 4 × (1 + 4) = 20개

즉, 20개의 스레드가 있어야 4개의 CPU가 놀지 않고 바쁘게 일할 수 있다는 뜻.
```

### 실제로 이 공식을 언제 사용할까?

공식에 따르면 CPU Bound 작업이 많으면 코어수와 스레드 수의 차이가 별로 없다.  
I/O Bound 작업이 많으면 코어 수 보다 스레드 수를 늘려야한다.

더 자세히 설명하자면...

- cpu 대기시간이 서비스 시간보다 짧다면 cpu 개수보다 스레드가 적어야 성능이 좋다.이유는 대기가 짧기에 (콘텍스트 스위칭 비용이 적기에) 스레드 개수 적어도 상관없다. → 대기 시간이 서비스 시간보다 짧으면 cpu를 사용하는 시간이 길다는 것 = 스레드를 아무리 늘려도 cpu를 사용하는 시간이 상대적으로 기니까 대기하는 스레드가 늘어날 뿐 이득이 되지 않는다.
- 반대로 대기시간이 서비스 처리 시간보다 많다면 스레드 수는 cpu개수보다 많아야 성능이 좋다.이유는 대기가 길기에 (콘텍스트 스위칭 비용(PCB 정보 저장 및 복원 + 캐시 비용)이 많기에) cpu 유휴(idle) 시간이 생긴다. 따라서 스레드 개수를 늘려 대기를 줄여야 한다.

**I/O Bound 작업**  
네트워크 호출, 디스크 읽기, DB 접근 등에서 스레드가 자주 블로킹된다면 공식에 따라 스레드 수를 일시적으로 늘려 cpu 자원을 효율적으로 활용하도록 한다.

**CPU Bound 작업**
CPU만 사용하고 대기 시간이 거의 없다면 waitTime 이 0에 수렴 -> 스레드 수 = 코어수 또는 +1 수준 -> 공식을 보면 대기시간이 0 이 되므로 스레드 수는 코어수가 된다.

**목표 활용률 조절 가능**  
`U`를 0.8 ~0.9로 두면, 시스템 부하 증가 시에도 안정성 유지

**테스트 기반 튜닝 필수**  
공식은 출발점일 뿐이고, 실제 워크로드 특성에 따라 실험(load testing)하여 조정해야한다.

### 정리

공식: N_cpu × U × (1 + waitTime/serviceTime)
사용 시점

- I/O 작업이 많을 때 → 스레드 수를 공식으로 계산 (일반적으로 코어수보다 스레드 개수를 늘린다.)
- CPU 작업 위주일때 → 스레드 수 ≈ 코어 수 또는 +1 (코어스와 비슷하게 설정)
- 실무 팁: 표준값으로 시작 → 모니터링 & 부하 테스트 → 조정

[스레드 풀의 적절한 크기를 구하는 합리적인 방법](https://medium.com/@10x.developer.kr/%EC%8A%A4%EB%A0%88%EB%93%9C-%ED%92%80%EC%9D%98-%EC%A0%81%EC%A0%88%ED%95%9C-%ED%81%AC%EA%B8%B0%EB%A5%BC-%EA%B5%AC%ED%95%98%EB%8A%94-%ED%95%A9%EB%A6%AC%EC%A0%81%EC%9D%B8-%EB%B0%A9%EB%B2%95-7af84b615623) 이글 에서는 CPU 코어수 \* (1/cpu사용시간)라고 한다. 하지만 내가 알고 있는 공식과 약간 다르다.

> CPU 코어수 \* (1/cpu사용시간)  
> 1/cpu 사용시간 = 1/cpu 사용률 = (서비스 시간 + 대기 시간) / 서비스 시간 = 1 + (대기 시간 / 서비스 시간)

- cpu 수 \* (1+대기/서비스) : 대기 시간이 길수록 더 많은 스레드 필요
- cpu 수 \* (1/cpu 사용률) : cpu를 적게 쓰면 더 많은 스레드가 필요

말만 다르지 똑같은 의미이다.

스레드 풀로 처리하고 싶은 요청의 전체 처리 시간 대비 CPU를 사용하는 시간의 역수를 코어 개수에 곱해주면 된다.

예를 들어서, CPU 코어 개수가 1개이고 어떤 요청을 처리할 때 CPU를 요청 처리 시간 중 1/3만 사용한다면 스레드 풀 크기는 최소 3은 되어야한다. 그래야 cpu가 작업을 완료했는데 스레드 풀 개수가 부족해서 요청을 못받으면 cpu는 일을 하지 않고 놀게 되는 리소스 낭비가 생긴다.

CPU 코어가 여러개이면 코어 개수 만큼 스레드 풀 크기를 늘려주면된다.

## 그럼 이 스레드 풀 크기로 1초당 처리할 수 있는 요청 수는?

> 리틀의 법칙, **L = λ W**
> 스레드 풀에서 사용중인 스레드 수 = 1초당 요청 수 \* 평균 요청 처리 시간

리틀의 법칙으로 1초당 처리할 수 있는 요청 수를 구할 수 있다.
예를 들어서, 스레드 풀의 크기가 50이고 평균 요청 처리 시간이 한 요청에 100ms라면 이 스레드 풀 크기로 우리가 1초당 처리할 수 있는 요청 수는 대략 50/0.1sec = 500 개 가 된다.
50 개의 스레드가 있고 이 스레드 들이 각각 요청 1개를 처리하는데 0.1 초가 걸린므로, 1초엔 500 개의 요청을 이 스레드 풀로 처리할 수 있다.

### 주의할 점은 데이터베이스의 커넥션 풀을 스레드 풀 내부의 요청들이 사용한다면 커넥션 풀의 크기를 꼭 확인해봐야한다.

![](../images/Pasted%20image%2020250718232017.png)
커넥션 풀을 많이 설정하였지만 DB 커넥션이 부족해서 DB 커넥션에서 병목현상이 발생할 수 있기 때문이다.

이렇게 데이터베이스 등의 외부 자원의 커넥션 풀을 스레드 풀 내부의 요청들에서 사용한다면 꼭 커넥션 풀 크기를 확인해봐야한다.
반대로 데이터베이스 커넥션 풀이 충분한데 스레드 풀이 작은 경우도, 자원을 제대로 활용하지 못하는 경우이다. 스레드 풀의 크기가 100인데 데이터베이스 커넥션 풀이 200이라면 데이터베이스 커넥션을 충분히 사용하지 못하는 경우이다.

또한 데이터베이스 커넥션 풀을 여러 스레드 풀이 함께 사용할 수 있다.

## 스레드 풀 크기를 정확히 계산하는 것보다, 부족하거나 과도하게 세팅하는 것을 막는게 중요

스레드 풀을 조정하기 위해서 매우 많은 요소를 세심하게 따져봐야한다.

- cpu 사용률
- 스레드풀을 사용하는 외부 자원
- 메모리 사용률(스레드가 많아지면 메모리 사용률도 늘어날 것이고, 여기서 메모리가 감당 가능한지도 살펴봐야한다.)
- 마치 서비스 벤치마크 테스트하는 것처럼...

cpu가 놀고 있거나 너무 과도하게 크게 설정하여 더 많은 자원을 불필요하게 사용하지 않게 만드는 것이 중요하다.

결국 스레드 개수 조정도 실험과학처럼 여러 시도를 해보고, 고쳐야한다고 생각한다.

## 이런 사고 방식을 어디에 활용할 수 있는가

스레드 풀 크기를 구하는 상황 이외에도 카프카 프로튜서와 컨슈머, 엘라스틱 서치 등의 세부 설정을 조절할 때 적절한 세팅값을 대략적으로 구하는 데 활용할 수 있다.

## 위 글을 바탕으로 내가 스레드 풀을 조절한 근거를 생각해보자

스레드 풀의 개수를 100으로 설정했다.

1. 운영 환경 분석을 안함. 공식을 활용하지 않음. io작업이 많다면 공식을 사용하는게 첫번째 발걸음?이라고 하는데, 스레드 개수 조정할 때 이 공식에 대해 알지 못하고 바로 스레드 개수를 직접 조정해 보면서 실험을 하였다.
2. 실험한 방법: StopWatch를 활용한 aop를 만들어서 메서드 속도 측정을 하였다.
3. 그 결과 스레드의 개수를 100으로 설정한 것이 제일 빠르다는 결론이 도출.

그 당시에 스레드 풀 개수 공식에 대해 모르고 있었다는 거에 긍정적으로 평가하고 싶다. 만일 공식을 알고 있었다면 바로 스레드 풀 개수를 공식에 맞춰서 적용했을 텐데, 직접 운영환경에서 실험을 하면서 최적화하는 경험을 할 수 있었다는 것에 긍정적으로 평가하고 있다. 나중에 스레드 풀 개수를 조정할 일이 생기면 공식도 적용해 볼 것이지만, 애플레케이션의 cpu 사용률을 고려하여 직접 실험하면서 성능을 최적화활 수 있구나 라는 생각을 심어준 경험이었다.
forkJoinPool의 스레드 풀 사이즈가 코어수 - 1 이였으므로 이 스레드 풀은 cpu Bound 작업이 많을 경우 자원을 효율적으로 사용할 수 있는 스레드 풀임을 예상할 수 있다.

### 답변 정리

> 당시에는 스레드 풀 개수를 계산하는 공식이 있다는 사실을 알지 못했습니다. 대신 실험적인 접근을 택했는데요, StopWatch를 활용한 AOP 로직을 작성해서 특정 메서드의 처리 속도를 측정하며 스레드 개수를 조절했습니다.

> 실험 결과, 스레드 풀의 개수를 100으로 설정했을 때 가장 빠른 응답 속도를 보였고, 실제로 11초 이상 지연되던 작업이 절반 이하로 줄어드는 효과를 얻을 수 있었습니다.

> 이후 관련 공식을 학습하면서, 이론적으로도 시스템 자원의 특성과 작업 특성(IO bound) 등을 고려해야 한다는 걸 배웠고, 다음에는 이론과 실험을 병행해서 더 안정적인 튜닝을 할 수 있을 거라는 확신도 생겼습니다.

> 결과적으로 이 경험은, 실무에서 운영 환경을 직접 측정하고 최적화하는 문제 해결 역량을 길러줬고, 성능 개선은 단순히 "이론을 적용하는 것" 이상으로 현장 적응력이 필요하다는 걸 배운 좋은 기회였습니다.

### ForkJoinPool이 아닌 ThreadPoolTaskExecutor를 선택한 이유는 무엇인가요?

원래는 ForkJoinPool을 사용했었는데, forkJoinPool이 work steeling이라는 매커니즘으로 동작을 하는 스레드풀입니다. 따라서 작업량이 비슷한 task가 forkJoinPool에 할당이되면 해당 매커니즘을 사용하는 의미가 없었고, 오히려 각 스레드별로 개별큐를 생성하는 것에 자원을 사용하므로 낭비라고 생각했습니다. 그래서 스레드에 할당되는 작업의 처리량을 알기위한 방법은 찾지못하고, 이를 대략적으로 알 수 있는 방법이 기본 스레드 풀 방식을 사용하는 threadPoolExecutor를 쉽게 사용하도록 지원하는 스프릥의 thredPoolTaskExcetuor를 적용해보기로 했습니다. 그 결과 threadPoolTaskExcetor를 적용한것이 0.6초가량 더 빨랐고, 이결과를 통해 각 작업의 처리량에 차이가 별로 없음을 알게 되었습니다.

## ForkJoinPool

원래는 ForkJoinPool을 사용했었는데, forkJoinPool이 work steeling이라는 매커니즘으로 동작을 하는 스레드풀입니다. 따라서 작업량이 비슷한 task가 forkJoinPool에 할당이되면 해당 매커니즘을 사용하는 의미가 없었고, 오히려 각 스레드별로 개별큐를 생성하는 것에 자원을 사용하므로 낭비라고 생각했습니다. 그래서 스레드에 할당되는 작업의 처리량을 알기위한 방법은 찾지못하고, 이를 대략적으로 알 수 있는 방법이 기본 스레드 풀 방식을 사용하는 threadPoolExecutor를 쉽게 사용하도록 지원하는 스프릥의 thredPoolTaskExcetuor를 적용해보기로 했습니다. 그 결과 threadPoolTaskExcetor를 적용한것이 0.6초가량 더 빨랐고, 이결과를 통해 각 작업의 처리량에 차이가 별로 없음을 알게 되었습니다.

"ForkJoinPool은 병렬 스트림과 CompletableFuture가 사용하는 실행 메커니즘이자,  
고성능 작업 분할을 위한 핵심 프레임워크입니다."

## [ForkJoinPool의 필요성](https://github.com/xxyeon/TIL/blob/main/%ED%8F%AC%ED%8A%B8%ED%8F%B4%EB%A6%AC%EC%98%A4_%EC%A0%95%EB%A6%AC/threadPool.md)

일반적인 스레드 풀은 다음과 같은 한계가 있다.

1. 작업 분배의 불균현: 일부 스레드에 작업이 집중되는 현상 -> 작업을 쪼개서 균형을 맞춤
2. 작업 단위가 큰 경우 처리 시간예측의 어려움 -> 작업단위를 쪼갬
3. 멀티 코어 환경에서 효율적인 자원 활용의 어려움
   그래서 작업을 쪼갬으로서 forkJoinpool 대신 threadTaskPoolExecutor를 사용했다.

ForkJoinPool은 분할 정복(divide and conquer) 방식으로 작업을 처리하는 ExecutorService의 구현체입니다.  
일반 ThreadPool과의 주요 차이점은 **작업 분할(Fork)과 결과 합치기(Join)** 패러다임입니다.

```java
// 일반적인 ThreadPool 사용 예시
ExecutorService executorService = Executors.newFixedThreadPool(4);
Future<Integer> future = executorService.submit(() -> heavyComputation()); // 작업 생성
Integer result = future.get(); //작업 대기

// ForkJoinPool 사용 예시
ForkJoinPool forkJoinPool = ForkJoinPool.commonPool();
Integer result = forkJoinPool.invoke(new SumTask(0, 10000));
```

일반적인 스레드 풀은

- I/O작업, 네트워크 요청, DB 조회 등 병렬 처리가 필요하지만 작업 분할이 적절하지 않은 경

## work stealing 알고리즘

1. forkJoinPool은 외부에 제출된 ForkJoinTask를 Global Shared Queue 에 배치한다.
2. 각 스레드는 자신만의 workQueue를 가지고 있다.
3. 스레드가 자신만의 workQueue에서 push/pop 연산을 수행할 때는 동기화가 필요 없어 성능이 좋다.
4. 자신의 작업을 모두 처리한 스레드는 다른 스레드의 workQueue에서 작업을 훔쳐올 수 있다(Stealing)

## ThreadPoolExecutor

javadml ThreadPoolExecutor를 스프링 의 TaskExecutor로 추상화한것이다. 그리고 스레드 풀의 구성을 매우 편리하게 지원해준다.

### corePoolSize와 maxPoolsize

corePoolSize: 동시에 실행할 기본 스레드 수. 모든 스레드는 시간 초과될 수 있고 → 실행되고 있어야하는 최소 스레드 개수, allowCoreThreadTimeOut을 ture로 설정하면 corePoolsize는 0으로 설정된다.

maxPoolSize: 최대 스레드 개수를 지정한 것이다. maxPoolSize는 queueCapacity에 따라 달라진다. *ThreadPoolTaskExecutor는* 큐 에 있는 대기하고 있는 작업 수가 *queueCapacity를* 초과할 때만 새 스레드를 생성합니다 .(더이상 작업을 대기할 수 없으니까)

> _queueCapacity: 스레드를 할당받기 위해 대기하는 작업 대기시키는 큐_

ThreadPoolTaskExecutor의 디폴트값은 corePoolSize=1 maxPoolSize 무제한, queueCapacity 문제한이다. → 해당 스레드 풀을 사용하는 작업은 단일 스레드 환경

```java
@Test
public void whenCorePoolSizeFiveAndMaxPoolSizeTen_thenFiveThreads() {
    ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor();
    taskExecutor.setCorePoolSize(5);
    taskExecutor.setMaxPoolSize(10);
    taskExecutor.afterPropertiesSet();

    CountDownLatch countDownLatch = new CountDownLatch(10);
    this.startThreads(taskExecutor, countDownLatch, 10);

    while (countDownLatch.getCount() > 0) {
        Assert.assertEquals(5, taskExecutor.getPoolSize());
    }
}
```

maxPoolSize: 10, corePoolSize = 5, QueueCapacity가 무제한이므로 스레드는 5개만 실행된다.

```java
@Test
public void whenCorePoolSizeFiveAndMaxPoolSizeTenAndQueueCapacityTen_thenTenThreads() {
    ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor();
    taskExecutor.setCorePoolSize(5);
    taskExecutor.setMaxPoolSize(10);
    taskExecutor.setQueueCapacity(10);
    taskExecutor.afterPropertiesSet();

    CountDownLatch countDownLatch = new CountDownLatch(20);
    this.startThreads(taskExecutor, countDownLatch, 20);

    while (countDownLatch.getCount() > 0) {
        Assert.assertEquals(10, taskExecutor.getPoolSize());
    }
}
```

corePoolSize = 5, *queueCapacity를* 10으로 증가시키고 20개의 스레드를 시작

결과는? 10개의 스레드가 시작된다.

왜냐하면 10개의 스레드가 실행중인데 새로운 스레드가 필요한 상황(작업이 10개보다 많음), queueCapactiry를 확인해보니 10개로 제한되어있으므로 스레드를 새로 생성해준다.

*마찬가지로, queueCapactity를* 0으로 설정하고 10개의 작업만 시작한 경우 *ThreadPoolTaskExecutor* 에도 10개의 스레드가 있게 됩니다 .

## 정리

- 현재 스레드 수 < corePoolSize : 요청을 바로 새로운 스레드에 할당하여 실행
- corePoolSize만큼 스레드를 실행하고 있다면, 요청은 queueCapacity에 저장
- 큐도 꽉 찼다면, maxPoolSize까지 추가 생성
- maxPoolSize까지 스레드 생성되었다면, 요청 거부 RejectExecutionHandler 실행

## ForkjoinPool의 적합/부적합

적합

- 대량 데이터 처리
- 행렬 계산 및 수치 연산
- 그래프 알고리즘 처리
- 이미지 처리 및 렌더링 -> 순서 보장 상관없음
- CPU 집약적 병렬 작업
  부적합 (일반적인 스레드 풀이 적합)
- I/O 바운드 작업(파일, 네트워크) -> 순서를 보장해야하는데 작업을 쪼개면 안됨
- 데이터베이스 트랜잭션 처리
- 작업량이 적은 경우(오버헤드)
- 작업 간 의존성이 복잡한 경우
- 블로킹 작업이 많은 경우
