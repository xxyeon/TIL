# 스레드 풀 개수 조정 근거

핵심은 CPU의 노는 시간을 최대한 줄이도록 쓰레드 개수를 조정하면 된다.

## 쓰레드 풀의 적정 크기

스레드 수 = CPU 코어 수 × U × (1 + waitTime / serviceTime) -> Brian Goetz가 Java Concurrency in Practice에서 말한 공식이다. 이를 풀어서 설명하면 아래와 같다.

```
- 대기 시간: IO, 락 획득, 네트워크 응답 등으로 인해 CPU를 사용하지 않고 대기하는 시간
- 서비스시간: 실제 연산자(CPU-bound) 작업을 수행하는 시간
- 1+waitTime/serviceTime =  스레드 수를 증가시켜 CPU가 놀지 않고 계속 일하도록 보상하는 계수
 U(활용률): 1이면 100% 사용, 0.8이면 80% 목표

CPU 수: 4개
평균적으로: 1개의 스레드는 20ms 동안 CPU를 쓰고 이후 80ms는 I/O 응답을 기다림
→ wait / service = 80 / 20 = 4
→ 적정 스레드 수 ≈ 4 × (1 + 4) = 20개

즉, 20개의 스레드가 있어야 4개의 CPU가 놀지 않고 바쁘게 일할 수 있다는 뜻.
```

### 실제로 이 공식을 언제 사용할까?

**I/O Bound 작업**  
네트워크 호출, 디스크 읽기, DB 접근 등에서 스레드가 자주 블로킹된다면 공식에 따라 스레드 수를 일시적으로 늘려 cpu 자원을 효율적으로 활용하도록 한다.

**CPU Bound 작업**
CPU만 사용하고 대기 시간이 거의 없다면 waitTime 이 0에 수렴 -> 스레드 수 = 코어수 또는 +1 수준 -> 공식을 보면 대기시간이 0 이 되므로 스레드 수는 코어수가 된다.

**목표 활용률 조절 가능**  
`U`를 0.8 ~0.9로 두면, 시스템 부하 증가 시에도 안정성 유지

**테스트 기반 튜닝 필수**  
공식은 출발점일 뿐이고, 실제 워크로드 특성에 따라 실험(load testing)하여 조정해야한다.

### 정리

공식: N_cpu × U × (1 + waitTime/serviceTime)
사용 시점

- I/O 작업이 많을 때 → 스레드 수를 공식으로 계산
- CPU 작업 위주일때 → 스레드 수 ≈ 코어 수 또는 +1
- 실무 팁: 표준값으로 시작 → 모니터링 & 부하 테스트 → 조정

[스레드 풀의 적절한 크기를 구하는 합리적인 방법](https://medium.com/@10x.developer.kr/%EC%8A%A4%EB%A0%88%EB%93%9C-%ED%92%80%EC%9D%98-%EC%A0%81%EC%A0%88%ED%95%9C-%ED%81%AC%EA%B8%B0%EB%A5%BC-%EA%B5%AC%ED%95%98%EB%8A%94-%ED%95%A9%EB%A6%AC%EC%A0%81%EC%9D%B8-%EB%B0%A9%EB%B2%95-7af84b615623) 이글 에서는 CPU 코어수 \* (1/cpu사용시간)라고 한다. 하지만 내가 알고 있는 공식과 약간 다르다.

> CPU 코어수 \* (1/cpu사용시간)  
> 1/cpu 사용시간 = 1/cpu 사용률 = (서비스 시간 + 대기 시간) / 서비스 시간 = 1 + (대기 시간 / 서비스 시간)

- cpu 수 \* (1+대기/서비스) : 대기 시간이 길수록 더 많은 스레드 필요
- cpu 수 \* (1/cpu 사용률) : cpu를 적게 쓰면 더 많은 스레드가 필요

말만 다르지 똑같은 의미이다.

스레드 풀로 처리하고 싶은 요청의 전체 처리 시간 대비 CPU를 사용하는 시간의 역수를 코어 개수에 곱해주면 된다.

예를 들어서, CPU 코어 개수가 1개이고 어떤 요청을 처리할 때 CPU를 요청 처리 시간 중 1/3만 사용한다면 스레드 풀 크기는 최소 3은 되어야한다. 그래야 cpu가 작업을 완료했는데 스레드 풀 개수가 부족해서 요청을 못받으면 cpu는 일을 하지 않고 놀게 되는 리소스 낭비가 생긴다.

CPU 코어가 여러개이면 코어 개수 만큼 스레드 풀 크기를 늘려주면된다.

## 그럼 이 스레드 풀 크기로 1초당 처리할 수 있는 요청 수는?

> 리틀의 법칙, **L = λ W**
> 스레드 풀에서 사용중인 스레드 수 = 1초당 요청 수 \* 평균 요청 처리 시간

리틀의 법칙으로 1초당 처리할 수 있는 요청 수를 구할 수 있다.
예를 들어서, 스레드 풀의 크기가 50이고 평균 요청 처리 시간이 한 요청에 100ms라면 이 스레드 풀 크기로 우리가 1초당 처리할 수 있는 요청 수는 대략 50/0.1sec = 500 개 가 된다.
50 개의 스레드가 있고 이 스레드 들이 각각 요청 1개를 처리하는데 0.1 초가 걸린므로, 1초엔 500 개의 요청을 이 스레드 풀로 처리할 수 있다.

### 주의할 점은 데이터베이스의 커넥션 풀을 스레드 풀 내부의 요청들이 사용한다면 커넥션 풀의 크기를 꼭 확인해봐야한다.

![](../images/Pasted%20image%2020250718232017.png)
커넥션 풀을 많이 설정하였지만 DB 커넥션이 부족해서 DB 커넥션에서 병목현상이 발생할 수 있기 때문이다.

이렇게 데이터베이스 등의 외부 자원의 커넥션 풀을 스레드 풀 내부의 요청들에서 사용한다면 꼭 커넥션 풀 크기를 확인해봐야한다.
반대로 데이터베이스 커넥션 풀이 충분한데 스레드 풀이 작은 경우도, 자원을 제대로 활용하지 못하는 경우이다. 스레드 풀의 크기가 100인데 데이터베이스 커넥션 풀이 200이라면 데이터베이스 커넥션을 충분히 사용하지 못하는 경우이다.

또한 데이터베이스 커넥션 풀을 여러 스레드 풀이 함께 사용할 수 있다.

## 스레드 풀 크기를 정확히 계산하는 것보다, 부족하거나 과도하게 세팅하는 것을 막는게 중요

스레드 풀을 조정하기 위해서 매우 많은 요소를 세심하게 따져봐야한다.

- cpu 사용률
- 스레드풀을 사용하는 외부 자원
- 메모리 사용률(스레드가 많아지면 메모리 사용률도 늘어날 것이고, 여기서 메모리가 감당 가능한지도 살펴봐야한다.)
- 마치 서비스 벤치마크 테스트하는 것처럼...

cpu가 놀고 있거나 너무 과도하게 크게 설정하여 더 많은 자원을 불필요하게 사용하지 않게 만드는 것이 중요하다.

결국 스레드 개수 조정도 실험과학처럼 여러 시도를 해보고, 고쳐야한다고 생각한다.

## 이런 사고 방식을 어디에 활용할 수 있는가

스레드 풀 크기를 구하는 상황 이외에도 카프카 프로튜서와 컨슈머, 엘라스틱 서치 등의 세부 설정을 조절할 때 적절한 세팅값을 대략적으로 구하는 데 활용할 수 있다.

## 위 글을 바탕으로 내가 스레드 풀을 조절한 근거를 생각해보자

스레드 풀의 개수를 100으로 설정했다.

1. 운영 환경 분석을 안함. 공식을 활용하지 않음. io작업이 많다면 공식을 사용하는게 첫번째 발걸음?이라고 하는데, 스레드 개수 조정할 때 이 공식에 대해 알지 못하고 바로 스레드 개수를 직접 조정해 보면서 실험을 하였다.
2. 실험한 방법: StopWatch를 활용한 aop를 만들어서 메서드 속도 측정을 하였다.
3. 그 결과 스레드의 개수를 100으로 설정한 것이 제일 빠르다는 결론이 도출.

그 당시에 스레드 풀 개수 공식에 대해 모르고 있었다는 거에 긍정적으로 평가하고 싶다. 만일 공식을 알고 있었다면 바로 스레드 풀 개수를 공식에 맞춰서 적용했을 텐데, 직접 운영환경에서 실험을 하면서 최적화하는 경험을 할 수 있었다는 것에 긍정적으로 평가하고 있다. 나중에 스레드 풀 개수를 조정할 일이 생기면 공식도 적용해 볼 것이지만, 애플레케이션의 cpu 사용률을 고려하여 직접 실험하면서 성능을 최적화활 수 있구나 라는 생각을 심어준 경험이었다.
forkJoinPool의 스레드 풀 사이즈가 코어수 - 1 이였으므로 이 스레드 풀은 cpu Bound 작업이 많을 경우 자원을 효율적으로 사용할 수 있는 스레드 풀임을 예상할 수 있다.

### 답변 정리

> 당시에는 스레드 풀 개수를 계산하는 공식이 있다는 사실을 알지 못했습니다. 대신 실험적인 접근을 택했는데요, StopWatch를 활용한 AOP 로직을 작성해서 특정 메서드의 처리 속도를 측정하며 스레드 개수를 조절했습니다.

> 실험 결과, 스레드 풀의 개수를 100으로 설정했을 때 가장 빠른 응답 속도를 보였고, 실제로 11초 이상 지연되던 작업이 절반 이하로 줄어드는 효과를 얻을 수 있었습니다.

> 이후 관련 공식을 학습하면서, 이론적으로도 시스템 자원의 특성과 작업 특성(IO bound) 등을 고려해야 한다는 걸 배웠고, 다음에는 이론과 실험을 병행해서 더 안정적인 튜닝을 할 수 있을 거라는 확신도 생겼습니다.

> 결과적으로 이 경험은, 실무에서 운영 환경을 직접 측정하고 최적화하는 문제 해결 역량을 길러줬고, 성능 개선은 단순히 "이론을 적용하는 것" 이상으로 현장 적응력이 필요하다는 걸 배운 좋은 기회였습니다.

### ForkJoinPool이 아닌 ThreadPoolTaskExecutor를 선택한 이유는 무엇인가요?

원래는 ForkJoinPool을 사용했었는데, forkJoinPool이 work steeling이라는 매커니즘으로 동작을 하는 스레드풀입니다. 따라서 작업량이 비슷한 task가 forkJoinPool에 할당이되면 해당 매커니즘을 사용하는 의미가 없었고, 오히려 각 스레드별로 개별큐를 생성하는 것에 자원을 사용하므로 낭비라고 생각했습니다. 그래서 스레드에 할당되는 작업의 처리량을 알기위한 방법은 찾지못하고, 이를 대략적으로 알 수 있는 방법이 기본 스레드 풀 방식을 사용하는 threadPoolExecutor를 쉽게 사용하도록 지원하는 스프릥의 thredPoolTaskExcetuor를 적용해보기로 했습니다. 그 결과 threadPoolTaskExcetor를 적용한것이 0.6초가량 더 빨랐고, 이결과를 통해 각 작업의 처리량에 차이가 별로 없음을 알게 되었습니다.

#ExecutorService
비동기 모드에서 작업 실행을 간소화하는 JDK API이다. 일반적으로 ExecutorService는 스레드 풀과 해당 스레드에 작업을 할당하는 API를 자동으로 제공합니다.
스레드 생성, 관리, 스케줄링의 복잡성을 추상화하여 실제 작업에 집중할 수 있게 해줍니다.
